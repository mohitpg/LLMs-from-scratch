{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from GPT import GPT\n",
    "\n",
    "# Hyperparameters\n",
    "NUMBER_OF_FILES=10\n",
    "batch_size = 4  # How many batches per training step\n",
    "context_length = 16  # Length of the token chunk each batch\n",
    "d_model = 64  # The size of our model token embeddings\n",
    "num_blocks = 8  # Number of transformer blocks\n",
    "num_heads = 4  # Number of heads in Multi-head attention\n",
    "learning_rate = 1e-3  # 0.001\n",
    "dropout = 0.1  # Dropout rate\n",
    "max_iters = 100  # Total of training iterations <- Change this to smaller number for testing\n",
    "eval_interval = 50  # How often to evaluate\n",
    "eval_iters = 20  # Number of iterations to average for evaluation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'  # Use GPU if it's available.\n",
    "max_token_value = 100079\n",
    "embed_table=nn.Embedding(num_embeddings=max_token_value+1,embedding_dim=d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "model = GPT(d_model,context_length,num_heads,num_blocks,embed_table,dropout)\n",
    "model.load_state_dict(torch.load(\"./modelGPT.pt\"))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "model.eval()\n",
    "start = 'Me : Hello . You :'\n",
    "start_ids = encoding.encode(start)\n",
    "x = (torch.tensor(start_ids, dtype=torch.long, device=device)[None, ...])\n",
    "y = model.generate(x, max_new_tokens=100)\n",
    "print(encoding.decode(y[0].tolist()))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
